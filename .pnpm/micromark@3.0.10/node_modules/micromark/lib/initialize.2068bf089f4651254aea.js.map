{"version":3,"file":".pnpm/micromark@3.0.10/node_modules/micromark/lib/initialize.2068bf089f4651254aea.js","mappings":"oKAUO,MAAMA,EAAU,CACrBC,SAIF,SAA2BC,GACzB,MAAMC,EAAeD,EAAQE,QAC3BC,KAAKC,OAAOC,WAAWC,gBAUzB,SAAoCC,GAClC,GAAa,OAATA,EAQJ,OAHAP,EAAQQ,MAAM,cACdR,EAAQS,QAAQF,GAChBP,EAAQU,KAAK,eACN,IAAAC,GAAaX,EAASC,EAAc,cAPzCD,EAAQS,QAAQF,MAWpB,SAA0BA,GAExB,OADAP,EAAQQ,MAAM,aACPI,EAAUL,MAnBnB,IAAIM,EACJ,OAAOZ,EAsBP,SAASW,EAAUL,GACjB,MAAMO,EAAQd,EAAQQ,MAAM,YAAa,CACvCO,YAAa,OACbF,SAAAA,IAQF,OALIA,IACFA,EAASG,KAAOF,GAGlBD,EAAWC,EACJG,EAAKV,GAId,SAASU,EAAKV,GACZ,OAAa,OAATA,GACFP,EAAQU,KAAK,aACbV,EAAQU,KAAK,kBACbV,EAAQS,QAAQF,KAId,QAAmBA,IACrBP,EAAQS,QAAQF,GAChBP,EAAQU,KAAK,aACNE,IAGTZ,EAAQS,QAAQF,GACTU,O,uFCxDJ,MAAMC,EAAW,CACtBnB,SASF,SAA4BC,GAC1B,MAAMmB,EAAOhB,KAGPiB,EAAQ,GACd,IAGIC,EAGAC,EAGAC,EATAC,EAAY,EAUhB,OAAOC,EAGP,SAASA,EAAMlB,GAWb,GAAIiB,EAAYJ,EAAMM,OAAQ,CAC5B,MAAMC,EAAOP,EAAMI,GAEnB,OADAL,EAAKS,eAAiBD,EAAK,GACpB3B,EAAQE,QACbyB,EAAK,GAAGE,aACRC,EACAC,EAHK/B,CAILO,GAGJ,OAAOwB,EAAmBxB,GAI5B,SAASuB,EAAiBvB,GAKxB,GAJAiB,IAIIL,EAAKS,eAAeI,WAAY,CAClCb,EAAKS,eAAeI,gBAAaC,EAE7BZ,GACFa,IAIF,MAAMC,EAAmBhB,EAAKiB,OAAOV,OACrC,IAGIW,EAHAC,EAAkBH,EAKtB,KAAOG,KACL,GACsC,SAApCnB,EAAKiB,OAAOE,GAAiB,IACY,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAChC,CACAF,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,MAIJC,EAAejB,GAEf,IAAIkB,EAAQP,EAEZ,KAAOO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAMG,OAAOC,OAAO,GAAIP,GAC9CK,IAWF,OARA,OACEvB,EAAKiB,OACLE,EAAkB,EAClB,EACAnB,EAAKiB,OAAOS,MAAMV,IAGpBhB,EAAKiB,OAAOV,OAASgB,EACdX,EAAmBxB,GAG5B,OAAOkB,EAAMlB,GAIf,SAASwB,EAAmBxB,GAM1B,GAAIiB,IAAcJ,EAAMM,OAAQ,CAI9B,IAAKL,EACH,OAAOyB,EAAkBvC,GAK3B,GAAIc,EAAU0B,kBAAoB1B,EAAU0B,iBAAiBC,SAC3D,OAAOC,EAAU1C,GAKnBY,EAAK+B,UAAYC,QACf9B,EAAU0B,mBAAqB1B,EAAU+B,+BAK7C,OADAjC,EAAKS,eAAiB,GACf5B,EAAQqD,MACbC,EACAC,EACAC,EAHKxD,CAILO,GAIJ,SAASgD,EAAqBhD,GAG5B,OAFIc,GAAWa,IACfO,EAAejB,GACRsB,EAAkBvC,GAI3B,SAASiD,EAAsBjD,GAG7B,OAFAY,EAAKf,OAAOqD,KAAKtC,EAAKuC,MAAMC,MAAQnC,IAAcJ,EAAMM,OACxDH,EAAkBJ,EAAKuC,MAAME,OACtBX,EAAU1C,GAInB,SAASuC,EAAkBvC,GAGzB,OADAY,EAAKS,eAAiB,GACf5B,EAAQE,QACboD,EACAO,EACAZ,EAHKjD,CAILO,GAIJ,SAASsD,EAAkBtD,GAIzB,OAHAiB,IACAJ,EAAM0C,KAAK,CAAC3C,EAAK4B,iBAAkB5B,EAAKS,iBAEjCkB,EAAkBvC,GAI3B,SAAS0C,EAAU1C,GACjB,OAAa,OAATA,GACEc,GAAWa,IACfO,EAAe,QACfzC,EAAQS,QAAQF,KAIlBc,EAAYA,GAAaF,EAAKf,OAAO2D,KAAK5C,EAAKuC,OAC/C1D,EAAQQ,MAAM,YAAa,CACzBO,YAAa,OACbF,SAAUS,EACV0C,WAAY3C,IAEP4C,EAAa1D,IAItB,SAAS0D,EAAa1D,GACpB,OAAa,OAATA,GACF2D,EAAalE,EAAQU,KAAK,cAAc,GACxC+B,EAAe,QACfzC,EAAQS,QAAQF,KAId,QAAmBA,IACrBP,EAAQS,QAAQF,GAChB2D,EAAalE,EAAQU,KAAK,cAE1Bc,EAAY,EACZL,EAAK+B,eAAYjB,EACVR,IAGTzB,EAAQS,QAAQF,GACT0D,GAQT,SAASC,EAAapD,EAAOqD,GAC3B,MAAMC,EAASjD,EAAKkD,YAAYvD,GAwChC,GAvCIqD,GAAKC,EAAON,KAAK,MACrBhD,EAAMD,SAAWS,EACbA,IAAYA,EAAWN,KAAOF,GAClCQ,EAAaR,EACbO,EAAUiD,WAAWxD,EAAMW,OAC3BJ,EAAUkD,MAAMH,GAkCZjD,EAAKf,OAAOqD,KAAK3C,EAAMW,MAAMkC,MAAO,CACtC,IAAIjB,EAAQrB,EAAUe,OAAOV,OAE7B,KAAOgB,KACL,GAEErB,EAAUe,OAAOM,GAAO,GAAGjB,MAAMmC,OAASrC,KACxCF,EAAUe,OAAOM,GAAO,GAAGF,KAC3BnB,EAAUe,OAAOM,GAAO,GAAGF,IAAIoB,OAASrC,GAI1C,OAKJ,MAAMY,EAAmBhB,EAAKiB,OAAOV,OACrC,IAGI8C,EAGAnC,EANAC,EAAkBH,EAQtB,KAAOG,KACL,GACsC,SAApCnB,EAAKiB,OAAOE,GAAiB,IACY,cAAzCnB,EAAKiB,OAAOE,GAAiB,GAAGC,KAChC,CACA,GAAIiC,EAAM,CACRnC,EAAQlB,EAAKiB,OAAOE,GAAiB,GAAGE,IACxC,MAGFgC,GAAO,EAQX,IAJA/B,EAAejB,GAEfkB,EAAQP,EAEDO,EAAQvB,EAAKiB,OAAOV,QACzBP,EAAKiB,OAAOM,GAAO,GAAGF,IAAMG,OAAOC,OAAO,GAAIP,GAC9CK,KAGF,OACEvB,EAAKiB,OACLE,EAAkB,EAClB,EACAnB,EAAKiB,OAAOS,MAAMV,IAGpBhB,EAAKiB,OAAOV,OAASgB,GAQzB,SAASD,EAAegC,GACtB,IAAI/B,EAAQtB,EAAMM,OAElB,KAAOgB,KAAU+B,GAAM,CACrB,MAAMC,EAAQtD,EAAMsB,GACpBvB,EAAKS,eAAiB8C,EAAM,GAC5BA,EAAM,GAAGhE,KAAKiE,KAAKxD,EAAMnB,GAG3BoB,EAAMM,OAAS+C,EAGjB,SAASvC,IACPb,EAAUkD,MAAM,CAAC,OACjBjD,OAAaW,EACbZ,OAAYY,EACZd,EAAKS,eAAeI,gBAAaC,KA/U/BqB,EAAqB,CACzBvD,SAmVF,SAA2BC,EAAS4E,EAAIC,GACtC,OAAO,IAAAlE,GACLX,EACAA,EAAQE,QAAQC,KAAKC,OAAOC,WAAWa,SAAU0D,EAAIC,GACrD,aACA1E,KAAKC,OAAOC,WAAWyE,QAAQC,KAAKC,SAAS,qBAAkB/C,EAAY,M,uFCxWxE,MAAM8B,EAAO,CAClBhE,SAIF,SAAwBC,GACtB,MAAMmB,EAAOhB,KACP8E,EAAUjF,EAAQE,QAEtB,KAmBF,SAAuBK,GACrB,GAAa,OAATA,EASJ,OAJAP,EAAQQ,MAAM,mBACdR,EAAQS,QAAQF,GAChBP,EAAQU,KAAK,mBACbS,EAAK4B,sBAAmBd,EACjBgD,EARLjF,EAAQS,QAAQF,KAnBlBP,EAAQE,QACNC,KAAKC,OAAOC,WAAW6E,YACvBC,GACA,IAAAxE,GACEX,EACAA,EAAQE,QACNC,KAAKC,OAAOC,WAAW0D,KACvBoB,EACAnF,EAAQE,QAAQ,IAASiF,IAE3B,gBAIN,OAAOF,EAiBP,SAASE,EAAe5E,GACtB,GAAa,OAATA,EASJ,OAJAP,EAAQQ,MAAM,cACdR,EAAQS,QAAQF,GAChBP,EAAQU,KAAK,cACbS,EAAK4B,sBAAmBd,EACjBgD,EARLjF,EAAQS,QAAQF,O,sGC9Cf,MAAM6E,EAAW,CACtBC,WAAYC,KAEDC,EAASC,EAAkB,UAC3BC,EAAOD,EAAkB,QAMtC,SAASA,EAAkBE,GACzB,MAAO,CACL3F,SAOF,SAAwBC,GACtB,MAAMmB,EAAOhB,KACPE,EAAaF,KAAKC,OAAOC,WAAWqF,GACpCD,EAAOzF,EAAQE,QAAQG,EAAYoB,EAAOkE,GAChD,OAAOlE,EAGP,SAASA,EAAMlB,GACb,OAAOqF,EAAQrF,GAAQkF,EAAKlF,GAAQoF,EAAQpF,GAI9C,SAASoF,EAAQpF,GACf,GAAa,OAATA,EAOJ,OAFAP,EAAQQ,MAAM,QACdR,EAAQS,QAAQF,GACTU,EANLjB,EAAQS,QAAQF,GAUpB,SAASU,EAAKV,GACZ,OAAIqF,EAAQrF,IACVP,EAAQU,KAAK,QACN+E,EAAKlF,KAGdP,EAAQS,QAAQF,GACTU,GAOT,SAAS2E,EAAQrF,GACf,GAAa,OAATA,EACF,OAAO,EAGT,MAAMsF,EAAOxF,EAAWE,GACxB,IAAImC,GAAS,EAEb,GAAImD,EACF,OAASnD,EAAQmD,EAAKnE,QAAQ,CAC5B,MAAMC,EAAOkE,EAAKnD,GAElB,IAAKf,EAAKd,UAAYc,EAAKd,SAAS8D,KAAKxD,EAAMA,EAAKN,UAClD,OAAO,EAKb,OAAO,IA9DTwE,WAAYC,EACA,SAAVI,EAAmBI,OAAyB7D,IAsElD,SAASqD,EAAeS,GACtB,OAGA,SAAwB3D,EAAQ4D,GAC9B,IAGIxF,EAHAkC,GAAS,EAMb,OAASA,GAASN,EAAOV,aACTO,IAAVzB,EACE4B,EAAOM,IAAoC,SAA1BN,EAAOM,GAAO,GAAGH,OACpC/B,EAAQkC,EACRA,KAEQN,EAAOM,IAAoC,SAA1BN,EAAOM,GAAO,GAAGH,OAExCG,IAAUlC,EAAQ,IACpB4B,EAAO5B,GAAO,GAAGgC,IAAMJ,EAAOM,EAAQ,GAAG,GAAGF,IAC5CJ,EAAO6D,OAAOzF,EAAQ,EAAGkC,EAAQlC,EAAQ,GACzCkC,EAAQlC,EAAQ,GAGlBA,OAAQyB,GAIZ,OAAO8D,EAAgBA,EAAc3D,EAAQ4D,GAAW5D,GAe5D,SAAS0D,EAAuB1D,EAAQ4D,GACtC,IAAIE,EAAa,EAEjB,OAASA,GAAc9D,EAAOV,QAC5B,IACGwE,IAAe9D,EAAOV,QACU,eAA/BU,EAAO8D,GAAY,GAAG3D,OACW,SAAnCH,EAAO8D,EAAa,GAAG,GAAG3D,KAC1B,CACA,MAAMtB,EAAOmB,EAAO8D,EAAa,GAAG,GAC9BC,EAASH,EAAQ3B,YAAYpD,GACnC,IAKImF,EALA1D,EAAQyD,EAAOzE,OACf2E,GAAe,EACf5B,EAAO,EAKX,KAAO/B,KAAS,CACd,MAAM4D,EAAQH,EAAOzD,GAErB,GAAqB,iBAAV4D,EAAoB,CAG7B,IAFAD,EAAcC,EAAM5E,OAEyB,KAAtC4E,EAAMC,WAAWF,EAAc,IACpC5B,IACA4B,IAGF,GAAIA,EAAa,MACjBA,GAAe,OAEZ,IAAe,IAAXC,EACPF,GAAO,EACP3B,SACK,IAAe,IAAX6B,EAEJ,CAEL5D,IACA,OAIJ,GAAI+B,EAAM,CACR,MAAM3D,EAAQ,CACZyB,KACE2D,IAAe9D,EAAOV,QAAU0E,GAAQ3B,EAAO,EAC3C,aACA,oBACNhD,MAAO,CACLkC,KAAM1C,EAAKuB,IAAImB,KACf6C,OAAQvF,EAAKuB,IAAIgE,OAAS/B,EAC1Bb,OAAQ3C,EAAKuB,IAAIoB,OAASa,EAC1BgC,OAAQxF,EAAKQ,MAAMgF,OAAS/D,EAC5BgE,aAAchE,EACV2D,EACApF,EAAKQ,MAAMiF,aAAeL,GAEhC7D,IAAKG,OAAOC,OAAO,GAAI3B,EAAKuB,MAE9BvB,EAAKuB,IAAMG,OAAOC,OAAO,GAAI9B,EAAMW,OAE/BR,EAAKQ,MAAMmC,SAAW3C,EAAKuB,IAAIoB,OACjCjB,OAAOC,OAAO3B,EAAMH,IAEpBsB,EAAO6D,OACLC,EACA,EACA,CAAC,QAASpF,EAAOkF,GACjB,CAAC,OAAQlF,EAAOkF,IAElBE,GAAc,GAIlBA,IAIJ,OAAO9D","sources":["webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/initialize/content.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/initialize/document.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/initialize/flow.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/initialize/text.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n/** @type {Initializer} */\n\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n\n  let previous\n  return contentStart\n  /** @type {State} */\n\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n  /** @type {State} */\n\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n  /** @type {State} */\n\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n    return data(code)\n  }\n  /** @type {State} */\n\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Point} Point\n */\n\n/**\n * @typedef {Record<string, unknown>} StackState\n * @typedef {[Construct, StackState]} StackItem\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\n\nexport const document = {\n  tokenize: initializeDocument\n}\n/** @type {Construct} */\n\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n/** @type {Initializer} */\n\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {StackItem[]} */\n\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext|undefined} */\n\n  let childFlow\n  /** @type {Token|undefined} */\n\n  let childToken\n  /** @type {number} */\n\n  let lineStartOffset\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    } // Done.\n\n    return checkNewContainers(code)\n  }\n  /** @type {State} */\n\n  function documentContinue(code) {\n    continued++ // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n\n      if (childFlow) {\n        closeFlow()\n      } // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point|undefined} */\n\n      let point // Find the flow chunk.\n\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n\n      exitContainers(continued) // Fix positions.\n\n      let index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      } // Inject the exits earlier (they’re still also at the end).\n\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      ) // Discard the duplicate exits.\n\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n\n    return start(code)\n  }\n  /** @type {State} */\n\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      } // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      } // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n\n      self.interrupt = Boolean(\n        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack\n      )\n    } // Check if there is a new container.\n\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n  /** @type {State} */\n\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n  /** @type {State} */\n\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n  /** @type {State} */\n\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n  /** @type {State} */\n\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState]) // Try another.\n\n    return documentContinued(code)\n  }\n  /** @type {State} */\n\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n  /** @type {State} */\n\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow')) // Get ready for the next line.\n\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n  /**\n   * @param {Token} token\n   * @param {boolean} [eof]\n   * @returns {void}\n   */\n\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream) // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset && // …and either is not ended yet…\n          (!childFlow.events[index][1].end || // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      } // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean|undefined} */\n\n      let seen\n      /** @type {Point|undefined} */\n\n      let point // Find the previous chunk (the one before the lazy line).\n\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n\n          seen = true\n        }\n      }\n\n      exitContainers(continued) // Fix positions.\n\n      index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      } // Inject the exits earlier (they’re still also at the end).\n\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      ) // Discard the duplicate exits.\n\n      self.events.length = index\n    }\n  }\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n\n  function exitContainers(size) {\n    let index = stack.length // Exit open containers.\n\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContainer(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n */\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n}\n/** @type {Initializer} */\n\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding, // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n  /** @type {State} */\n\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n  /** @type {State} */\n\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Code} Code\n */\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n/**\n * @param {'string'|'text'} field\n * @returns {InitialConstruct}\n */\n\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n  /** @type {Initializer} */\n\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n    /** @type {State} */\n\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n    /** @type {State} */\n\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n    /** @type {State} */\n\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      } // Data.\n\n      effects.consume(code)\n      return data\n    }\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n\n      const list = constructs[code]\n      let index = -1\n\n      if (list) {\n        while (++index < list.length) {\n          const item = list[index]\n\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n\n      return false\n    }\n  }\n}\n/**\n * @param {Resolver} [extraResolver]\n * @returns {Resolver}\n */\n\nfunction createResolver(extraResolver) {\n  return resolveAllText\n  /** @type {Resolver} */\n\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number|undefined} */\n\n    let enter // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\n\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0 // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean|undefined} */\n\n      let tabs\n\n      while (index--) {\n        const chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        } // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n"],"names":["content","tokenize","effects","contentStart","attempt","this","parser","constructs","contentInitial","code","enter","consume","exit","f","lineStart","previous","token","contentType","next","data","document","self","stack","childFlow","childToken","lineStartOffset","continued","start","length","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","undefined","closeFlow","indexBeforeExits","events","point","indexBeforeFlow","type","end","exitContainers","index","Object","assign","slice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","_gfmTableDynamicInterruptHack","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","push","flow","_tokenizer","flowContinue","writeToChild","eof","stream","sliceStream","defineSkip","write","seen","size","entry","call","ok","nok","disable","null","includes","initial","flowInitial","afterConstruct","resolver","resolveAll","createResolver","string","initializeFactory","text","field","notText","atBreak","list","resolveAllLineSuffixes","extraResolver","context","splice","eventIndex","chunks","tabs","bufferIndex","chunk","charCodeAt","column","_index","_bufferIndex"],"sourceRoot":""}