{"version":3,"file":".pnpm/micromark@3.0.10/node_modules/micromark/lib.982dae2b24bd6a95e7c0.js","mappings":"ghBA2CO,SAASA,EAAgBC,EAAQC,EAAYC,GAElD,IAAIC,EAAQC,OAAOC,OACjBH,EACIE,OAAOC,OAAO,GAAIH,GAClB,CACEI,KAAM,EACNC,OAAQ,EACRC,OAAQ,GAEd,CACEC,OAAQ,EACRC,cAAe,IAKnB,MAAMC,EAAc,GAGdC,EAAuB,GAG7B,IAAIC,EAAS,GAGTC,EAAQ,GAGRC,GAAW,EAOf,MAAMC,EAAU,CACdC,QA2IF,SAAiBC,IACX,QAAmBA,IACrBf,EAAMG,OACNH,EAAMI,OAAS,EACfJ,EAAMK,SAAoB,IAAVU,EAAc,EAAI,EAClCC,MACmB,IAAVD,IACTf,EAAMI,SACNJ,EAAMK,UAGJL,EAAMO,aAAe,EACvBP,EAAMM,UAENN,EAAMO,eAIFP,EAAMO,eAAiBG,EAAOV,EAAMM,QAAQW,SAC9CjB,EAAMO,cAAgB,EACtBP,EAAMM,WAIVY,EAAQC,SAAWJ,EAEnBH,GAAW,GApKXQ,MAwKF,SAAeC,EAAMC,GAGnB,MAAMC,EAAQD,GAAU,GAKxB,OAJAC,EAAMF,KAAOA,EACbE,EAAMC,MAAQC,IACdP,EAAQQ,OAAOC,KAAK,CAAC,QAASJ,EAAOL,IACrCP,EAAMgB,KAAKJ,GACJA,GA/KPK,KAmLF,SAAcP,GACZ,MAAME,EAAQZ,EAAMkB,MAGpB,OAFAN,EAAMO,IAAML,IACZP,EAAQQ,OAAOC,KAAK,CAAC,OAAQJ,EAAOL,IAC7BK,GAtLPQ,QAASC,GA8LX,SAA+BC,EAAWC,GACxCC,EAAUF,EAAWC,EAAKnC,SA9L1BqC,MAAOJ,EAAiBK,GACxBC,UAAWN,EAAiBK,EAAmB,CAC7CC,WAAW,KASTpB,EAAU,CACdC,SAAU,KACVJ,KAAM,KACNwB,eAAgB,GAChBb,OAAQ,GACR7B,OAAAA,EACA2C,YAAAA,EACAC,eA6CF,SAAwBlB,EAAOmB,GAC7B,OAsYJ,SAAyBhC,EAAQgC,GAC/B,IAAIC,GAAS,EAGb,MAAMC,EAAS,GAGf,IAAIC,EAEJ,OAASF,EAAQjC,EAAOO,QAAQ,CAC9B,MAAM6B,EAAQpC,EAAOiC,GAGrB,IAAII,EAEJ,GAAqB,iBAAVD,EACTC,EAAQD,OAER,OAAQA,GACN,KAAM,EACJC,EAAQ,KACR,MAGF,KAAM,EACJA,EAAQ,KACR,MAGF,KAAM,EACJA,EAAQ,OACR,MAGF,KAAM,EACJA,EAAQL,EAAa,IAAM,KAC3B,MAGF,KAAM,EACJ,IAAKA,GAAcG,EAAO,SAC1BE,EAAQ,IACR,MAGF,QAEEA,EAAQC,OAAOC,aAAaH,GAIlCD,GAAmB,IAAXC,EACRF,EAAOjB,KAAKoB,GAGd,OAAOH,EAAOM,KAAK,IA7bVC,CAAgBX,EAAYjB,GAAQmB,IA7C3CjB,IAAAA,EACA2B,WA0DF,SAAoBL,GAClBvC,EAAYuC,EAAM5C,MAAQ4C,EAAM3C,OAChCY,KA3DAqC,MAwBF,SAAeC,GAIb,OAHA5C,GAAS,OAAKA,EAAQ4C,GAkDxB,WAEE,IAAIC,EAEJ,KAAOvD,EAAMM,OAASI,EAAOO,QAAQ,CACnC,MAAM6B,EAAQpC,EAAOV,EAAMM,QAE3B,GAAqB,iBAAVwC,EAOT,IANAS,EAAavD,EAAMM,OAEfN,EAAMO,aAAe,IACvBP,EAAMO,aAAe,GAIrBP,EAAMM,SAAWiD,GACjBvD,EAAMO,aAAeuC,EAAM7B,QAE3BuC,EAAGV,EAAMW,WAAWzD,EAAMO,oBAG5BiD,EAAGV,IAtEPY,GAEkC,OAA9BhD,EAAOA,EAAOO,OAAS,GAClB,IAGTkB,EAAUrC,EAAY,GAEtBoB,EAAQQ,QAAS,OAAWjB,EAAsBS,EAAQQ,OAAQR,GAC3DA,EAAQQ,UA3BjB,IAOIiC,EAPAC,EAAQ9D,EAAW+D,SAASC,KAAK5C,EAASL,GAa9C,OAJIf,EAAWiE,YACbtD,EAAqBkB,KAAK7B,GAGrBoB,EA0BP,SAASsB,EAAYjB,GACnB,OA6VJ,SAAqBb,EAAQa,GAC3B,MAAMyC,EAAazC,EAAMC,MAAMlB,OACzB2D,EAAmB1C,EAAMC,MAAMjB,aAC/B2D,EAAW3C,EAAMO,IAAIxB,OACrB6D,EAAiB5C,EAAMO,IAAIvB,aAGjC,IAAI6D,EAmBJ,OAjBIJ,IAAeE,EAEjBE,EAAO,CAAC1D,EAAOsD,GAAYV,MAAMW,EAAkBE,KAEnDC,EAAO1D,EAAO4C,MAAMU,EAAYE,GAE5BD,GAAoB,IAEtBG,EAAK,GAAKA,EAAK,GAAGd,MAAMW,IAGtBE,EAAiB,GAEnBC,EAAKzC,KAAKjB,EAAOwD,GAAUZ,MAAM,EAAGa,KAIjCC,EAvXEC,CAAY3D,EAAQa,GAI7B,SAASE,IACP,OAAOxB,OAAOC,OAAO,GAAIF,GAsD3B,SAASwD,EAAGzC,GACVH,OAAW0D,EACXX,EAAe5C,EACf6C,EAAQA,EAAM7C,GAmEhB,SAASsB,EAAkBkC,EAAGrC,GAC5BA,EAAKsC,UASP,SAASxC,EAAiByC,EAAUnD,GAClC,OAWA,SAAcoD,EAAYC,EAAaC,GAErC,IAAIC,EAGAC,EAGAC,EAGA7C,EACJ,OAAO8C,MAAMC,QAAQP,GAEjBQ,EAAuBR,GACvB,aAAcA,EACdQ,EAAuB,CAACR,KASGS,EARLT,EAYxB,SAAe3D,GACb,MAAMqE,EAAe,OAATrE,GAAiBoE,EAAIpE,GAC3BsE,EAAe,OAATtE,GAAiBoE,EAAIG,KAQjC,OAAOJ,EAPM,IAIPF,MAAMC,QAAQG,GAAOA,EAAMA,EAAM,CAACA,GAAO,MACzCJ,MAAMC,QAAQI,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAExCH,CAA6BnE,KAdxC,IAA+BoE,EAwB/B,SAASD,EAAuBK,GAI9B,OAHAV,EAAmBU,EACnBT,EAAiB,EAEG,IAAhBS,EAAKtE,OACA2D,EAGFY,EAAgBD,EAAKT,IAS9B,SAASU,EAAgBvD,GACvB,OAGA,SAAelB,GAYb,OAPAmB,EA4ER,WACE,MAAMuD,EAAahE,IACbiE,EAAgBxE,EAAQC,SACxBwE,EAAwBzE,EAAQ6D,iBAChCa,EAAmB1E,EAAQQ,OAAOT,OAClC4E,EAAab,MAAMjF,KAAKY,GAC9B,MAAO,CACL6D,QASF,WACExE,EAAQyF,EACRvE,EAAQC,SAAWuE,EACnBxE,EAAQ6D,iBAAmBY,EAC3BzE,EAAQQ,OAAOT,OAAS2E,EACxBjF,EAAQkF,EACR7E,KAdAjB,KAAM6F,GApFKE,GACPf,EAAmB9C,EAEdA,EAAU8D,UACb7E,EAAQ6D,iBAAmB9C,GAI3BA,EAAU+D,MACV9E,EAAQrB,OAAO6E,WAAWuB,QAAQX,KAAKY,SAASjE,EAAU+D,MAEnDG,IAGFlE,EAAU4B,SAASC,KAIxBxC,EAASrB,OAAOC,OAAOD,OAAOmG,OAAOlF,GAAUI,GAAUJ,EACzDL,EACAwF,EACAF,EAPKlE,CAQLlB,IAKN,SAASsF,EAAGtF,GAGV,OAFAH,GAAW,EACX6D,EAASM,EAAkB7C,GACpByC,EAIT,SAASwB,EAAIpF,GAIX,OAHAH,GAAW,EACXsB,EAAKsC,YAECM,EAAiBD,EAAiB5D,OAC/BuE,EAAgBX,EAAiBC,IAGnCF,IAUb,SAASzC,EAAUF,EAAWlC,GACxBkC,EAAU8B,aAAetD,EAAqByF,SAASjE,IACzDxB,EAAqBkB,KAAKM,GAGxBA,EAAUqE,UACZ,OACEpF,EAAQQ,OACR3B,EACAmB,EAAQQ,OAAOT,OAASlB,EACxBkC,EAAUqE,QAAQpF,EAAQQ,OAAO4B,MAAMvD,GAAOmB,IAI9Ce,EAAUsE,YACZrF,EAAQQ,OAASO,EAAUsE,UAAUrF,EAAQQ,OAAQR,IAyCzD,SAASF,IACHhB,EAAMG,QAAQK,GAAeR,EAAMI,OAAS,IAC9CJ,EAAMI,OAASI,EAAYR,EAAMG,MACjCH,EAAMK,QAAUG,EAAYR,EAAMG,MAAQ,I,2MC9czC,MAAM,EAAW,CACtB,GAAMoF,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAMA,EAAA,EACN,GAAM,KAIKiB,EAAiB,CAC5B,GAAMC,EAAA,GAIKC,EAAc,CACzB,EAAE,GAAI,IACN,EAAE,GAAI,IACN,GAAM,KAIK,EAAO,CAClB,GAAM,IACN,GAAM,IACN,GAAM,CAAC,IAAiB,KACxB,GAAM,IACN,GAAM,IACN,GAAM,IACN,GAAM,IACN,IAAO,KAIIC,EAAS,CACpB,GAAM,IACN,GAAM,KAIK,EAAO,CAClB,EAAE,GAAI,IACN,EAAE,GAAI,IACN,EAAE,GAAI,IACN,GAAM,IACN,GAAM,IACN,GAAMC,EAAA,EACN,GAAM,CAACC,EAAA,EAAU,KACjB,GAAM,IACN,GAAM,CAAC,IAAiB,KACxB,GAAM,IACN,GAAMD,EAAA,EACN,GAAM,KAIKE,EAAa,CACxBxB,KAAM,CAACsB,EAAA,EAAW,OAIPG,EAAmB,CAC9BzB,KAAM,CAAC,GAAI,KAIAW,EAAU,CACrBX,KAAM,ICpFD,SAAS0B,EAAMC,EAAU,IAG9B,MAMMpH,EAAS,CACbqH,QAAS,GACTC,KAAM,GACNzC,YATiB,OAEjB,CAAC,GAAmB0C,OAAOH,EAAQI,YAAc,KAQjDC,QAASlB,EAAOkB,EAAA,GAChBC,SAAUnB,EAAO,KACjBoB,KAAMpB,EAAOoB,EAAA,GACbb,OAAQP,EAAO,MACfqB,KAAMrB,EAAO,OAEf,OAAOvG,EAKP,SAASuG,EAAOsB,GACd,OAGA,SAAiB3H,GACf,OAAOH,EAAgBC,EAAQ6H,EAAS3H,O,iECvCvC,SAAS4H,EAAYjG,GAC1B,OAAQ,OAAYA,KAIpB,OAAOA,I,qDCAT,MAAMkG,EAAS,cAKR,SAASC,IACd,IAOIC,EAPA1H,EAAS,EACT2H,EAAS,GAGTvG,GAAQ,EAIZ,OAGA,SAAsBuB,EAAOiF,EAAUlG,GAErC,MAAMpB,EAAS,GAGf,IAAIuH,EAGAC,EAGAC,EAGAC,EAGArH,EAcJ,IAZAgC,EAAQgF,EAAShF,EAAMsF,SAASL,GAChCG,EAAgB,EAChBJ,EAAS,GAELvG,IAC0B,QAAxBuB,EAAMU,WAAW,IACnB0E,IAGF3G,OAAQ8C,GAGH6D,EAAgBpF,EAAM9B,QAAQ,CAOnC,GANA2G,EAAOU,UAAYH,EACnBF,EAAQL,EAAOW,KAAKxF,GACpBqF,EACEH,QAAyB3D,IAAhB2D,EAAMtF,MAAsBsF,EAAMtF,MAAQI,EAAM9B,OAC3DF,EAAOgC,EAAMU,WAAW2E,IAEnBH,EAAO,CACVF,EAAShF,EAAMO,MAAM6E,GACrB,MAGF,GAAa,KAATpH,GAAeoH,IAAkBC,GAAeN,EAClDpH,EAAOiB,MAAM,GACbmG,OAAmBxD,OAYnB,OAVIwD,IACFpH,EAAOiB,MAAM,GACbmG,OAAmBxD,GAGjB6D,EAAgBC,IAClB1H,EAAOiB,KAAKoB,EAAMO,MAAM6E,EAAeC,IACvChI,GAAUgI,EAAcD,GAGlBpH,GACN,KAAK,EACHL,EAAOiB,KAAK,OACZvB,IACA,MAGF,KAAK,EAIH,IAHA8H,EAA+B,EAAxBM,KAAKC,KAAKrI,EAAS,GAC1BM,EAAOiB,MAAM,GAENvB,IAAW8H,GAAMxH,EAAOiB,MAAM,GAErC,MAGF,KAAK,GACHjB,EAAOiB,MAAM,GACbvB,EAAS,EACT,MAGF,QACE0H,GAAmB,EACnB1H,EAAS,EAKf+H,EAAgBC,EAAc,EAShC,OANItG,IACEgG,GAAkBpH,EAAOiB,MAAM,GAC/BoG,GAAQrH,EAAOiB,KAAKoG,GACxBrH,EAAOiB,KAAK,OAGPjB","sources":["webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/create-tokenizer.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/constructs.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/parse.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/postprocess.js","webpack://tech-stack/./node_modules/.pnpm/micromark@3.0.10/node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n */\n\n/**\n * @typedef Info\n * @property {() => void} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_index'|'_bufferIndex'>} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n\n  const columnStart = {}\n  /** @type {Construct[]} */\n\n  const resolveAllConstructs = []\n  /** @type {Chunk[]} */\n\n  let chunks = []\n  /** @type {Token[]} */\n\n  let stack = []\n  /** @type {boolean|undefined} */\n\n  let consumed = true\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n  /**\n   * The state function.\n   *\n   * @type {State|void}\n   */\n\n  let state = initialize.tokenize.call(context, effects)\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n\n  let expectedCode\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n\n  return context\n  /** @type {TokenizeContext['write']} */\n\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main() // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n\n    addResult(initialize, 0) // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  } //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n  /** @type {TokenizeContext['sliceStream']} */\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n  /** @type {TokenizeContext['now']} */\n\n  function now() {\n    return Object.assign({}, point)\n  }\n  /** @type {TokenizeContext['defineSkip']} */\n\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  } //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index] // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n  /** @type {Effects['consume']} */\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    } // Not in a string chunk.\n\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++ // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    } // Expose the previous character.\n\n    context.previous = code // Mark as consumed.\n\n    consumed = true\n  }\n  /** @type {Effects['enter']} */\n\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n  /** @type {Effects['exit']} */\n\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {Record<string, unknown>} [fields]\n   */\n\n  function constructFactory(onreturn, fields) {\n    return hook\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Construct|Construct[]|ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State} [bogusState]\n     * @returns {State}\n     */\n\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Construct[]} */\n      let listOfConstructs\n      /** @type {number} */\n\n      let constructIndex\n      /** @type {Construct} */\n\n      let currentConstruct\n      /** @type {Info} */\n\n      let info\n      return Array.isArray(constructs)\n        ? /* c8 ignore next 1 */\n          handleListOfConstructs(constructs)\n        : 'tokenize' in constructs // @ts-expect-error Looks like a construct.\n        ? handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n\n      function handleMapOfConstructs(map) {\n        return start\n        /** @type {State} */\n\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Construct[]} list\n       * @returns {State}\n       */\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n\n        if (list.length === 0) {\n          return bogusState\n        }\n\n        return handleConstruct(list[constructIndex])\n      }\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n\n      function handleConstruct(construct) {\n        return start\n        /** @type {State} */\n\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n      /** @type {State} */\n\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n      /** @type {State} */\n\n      function nok(code) {\n        consumed = true\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Chunk[]} chunks\n * @param {Pick<Token, 'start'|'end'>} token\n * @returns {Chunk[]}\n */\n\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Chunk[]} */\n\n  let view\n\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view[0] = view[0].slice(startBufferIndex)\n    }\n\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Chunk[]} chunks\n * @param {boolean} [expandTabs=false]\n * @returns {string}\n */\n\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {string[]} */\n\n  const result = []\n  /** @type {boolean|undefined} */\n\n  let atTab\n\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n\n    let value\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n\n        case -4: {\n          value = '\\n'\n          break\n        }\n\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n\n    atTab = chunk === -2\n    result.push(value)\n  }\n\n  return result.join('')\n}\n","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {resolver as resolveText} from './initialize/text.js'\n/** @type {Extension['document']} */\n\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n}\n/** @type {Extension['contentInitial']} */\n\nexport const contentInitial = {\n  [91]: definition\n}\n/** @type {Extension['flowInitial']} */\n\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n}\n/** @type {Extension['flow']} */\n\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n}\n/** @type {Extension['string']} */\n\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n}\n/** @type {Extension['text']} */\n\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n}\n/** @type {Extension['insideSpan']} */\n\nexport const insideSpan = {\n  null: [attention, resolveText]\n}\n/** @type {Extension['attentionMarkers']} */\n\nexport const attentionMarkers = {\n  null: [42, 95]\n}\n/** @type {Extension['disable']} */\n\nexport const disable = {\n  null: []\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Create} Create\n */\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n/**\n * @param {ParseOptions} [options]\n * @returns {ParseContext}\n */\n\nexport function parse(options = {}) {\n  /** @type {FullNormalizedExtension} */\n  // @ts-expect-error `defaultConstructs` is full, so the result will be too.\n  const constructs = combineExtensions(\n    // @ts-expect-error Same as above.\n    [defaultConstructs].concat(options.extensions || [])\n  )\n  /** @type {ParseContext} */\n\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n  return parser\n  /**\n   * @param {InitialConstruct} initial\n   */\n\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Event} Event\n */\nimport {subtokenize} from 'micromark-util-subtokenize'\n/**\n * @param {Event[]} events\n * @returns {Event[]}\n */\n\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding} [encoding]\n * @param {boolean} [end=false]\n * @returns {Chunk[]}\n */\nconst search = /[\\0\\t\\n\\r]/g\n/**\n * @returns {Preprocessor}\n */\n\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean|undefined} */\n\n  let start = true\n  /** @type {boolean|undefined} */\n\n  let atCarriageReturn\n  return preprocessor\n  /** @type {Preprocessor} */\n\n  function preprocessor(value, encoding, end) {\n    /** @type {Chunk[]} */\n    const chunks = []\n    /** @type {RegExpMatchArray|null} */\n\n    let match\n    /** @type {number} */\n\n    let next\n    /** @type {number} */\n\n    let startPosition\n    /** @type {number} */\n\n    let endPosition\n    /** @type {Code} */\n\n    let code // @ts-expect-error `Buffer` does allow an encoding.\n\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        switch (code) {\n          case 0: {\n            chunks.push(65533)\n            column++\n            break\n          }\n\n          case 9: {\n            next = Math.ceil(column / 4) * 4\n            chunks.push(-2)\n\n            while (column++ < next) chunks.push(-1)\n\n            break\n          }\n\n          case 10: {\n            chunks.push(-4)\n            column = 1\n            break\n          }\n\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n\n    return chunks\n  }\n}\n"],"names":["createTokenizer","parser","initialize","from","point","Object","assign","line","column","offset","_index","_bufferIndex","columnStart","resolveAllConstructs","chunks","stack","consumed","effects","consume","code","accountForPotentialSkip","length","context","previous","enter","type","fields","token","start","now","events","push","exit","pop","end","attempt","constructFactory","construct","info","addResult","check","onsuccessfulcheck","interrupt","containerState","sliceStream","sliceSerialize","expandTabs","index","result","atTab","chunk","value","String","fromCharCode","join","serializeChunks","defineSkip","write","slice","chunkIndex","go","charCodeAt","main","expectedCode","state","tokenize","call","resolveAll","startIndex","startBufferIndex","endIndex","endBufferIndex","view","sliceChunks","undefined","_","restore","onreturn","constructs","returnState","bogusState","listOfConstructs","constructIndex","currentConstruct","Array","isArray","handleListOfConstructs","map","def","all","null","list","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","partial","name","disable","includes","nok","create","ok","resolve","resolveTo","contentInitial","definition","flowInitial","string","attention","autolink","insideSpan","attentionMarkers","parse","options","defined","lazy","concat","extensions","content","document","flow","text","initial","postprocess","search","preprocess","atCarriageReturn","buffer","encoding","match","next","startPosition","endPosition","toString","lastIndex","exec","Math","ceil"],"sourceRoot":""}